2023/02/13 23:22:13 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: win32
    Python: 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]
    CUDA available: True
    numpy_random_seed: 1040015893
    GPU 0: NVIDIA GeForce RTX 3080
    CUDA_HOME: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    MSVC: Microsoft(R) C/C++ Optimizing Compiler Version 19.29.30038.1 for x64
    GCC: n/a
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 4.7.0
    MMEngine: 0.5.0

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: None
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2023/02/13 23:22:13 - mmengine - INFO - Config:
norm_cfg = dict(type='BN', requires_grad=True, momentum=0.01)
data_preprocessor = dict(
    type='SegDataPreProcessor',
    mean=[123.675, 116.28, 103.53],
    std=[58.395, 57.12, 57.375],
    bgr_to_rgb=True,
    pad_val=0,
    seg_pad_val=255,
    size=(512, 512))
model = dict(
    type='EncoderDecoder',
    data_preprocessor=dict(
        type='SegDataPreProcessor',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        bgr_to_rgb=True,
        pad_val=0,
        seg_pad_val=255,
        size=(512, 512)),
    backbone=dict(
        type='FastSCNN',
        downsample_dw_channels=(32, 48),
        global_in_channels=64,
        global_block_channels=(64, 96, 128),
        global_block_strides=(2, 2, 1),
        global_out_channels=128,
        higher_in_channels=64,
        lower_in_channels=128,
        fusion_out_channels=128,
        out_indices=(0, 1, 2),
        norm_cfg=dict(type='SyncBN', requires_grad=True, momentum=0.01),
        align_corners=False),
    decode_head=dict(
        type='DepthwiseSeparableFCNHead',
        in_channels=128,
        channels=128,
        concat_input=False,
        num_classes=21,
        in_index=-1,
        norm_cfg=dict(type='SyncBN', requires_grad=True, momentum=0.01),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1)),
    auxiliary_head=[
        dict(
            type='FCNHead',
            in_channels=128,
            channels=32,
            num_convs=1,
            num_classes=21,
            in_index=-2,
            norm_cfg=dict(type='BN', requires_grad=True, momentum=0.01),
            concat_input=False,
            align_corners=False,
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=0.4)),
        dict(
            type='FCNHead',
            in_channels=64,
            channels=32,
            num_convs=1,
            num_classes=21,
            in_index=-3,
            norm_cfg=dict(type='BN', requires_grad=True, momentum=0.01),
            concat_input=False,
            align_corners=False,
            loss_decode=dict(
                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=0.4))
    ],
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'PascalVOCDataset'
data_root = 'data/VOCdevkit/VOC2012'
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='RandomResize',
        scale=(2048, 512),
        ratio_range=(0.5, 2.0),
        keep_ratio=True),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs')
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', scale=(2048, 512), keep_ratio=True),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs')
]
img_ratios = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]
tta_pipeline = [
    dict(type='LoadImageFromFile', backend_args=dict(backend='local')),
    dict(
        type='TestTimeAug',
        transforms=[[{
            'type': 'Resize',
            'scale_factor': 0.5,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 0.75,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.0,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.25,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.5,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.75,
            'keep_ratio': True
        }],
                    [{
                        'type': 'RandomFlip',
                        'prob': 0.0,
                        'direction': 'horizontal'
                    }, {
                        'type': 'RandomFlip',
                        'prob': 1.0,
                        'direction': 'horizontal'
                    }], [{
                        'type': 'LoadAnnotations'
                    }], [{
                        'type': 'PackSegInputs'
                    }]])
]
train_dataloader = dict(
    batch_size=4,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='InfiniteSampler', shuffle=True),
    dataset=dict(
        type='PascalVOCDataset',
        data_root='data/VOCdevkit/VOC2012',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        ann_file='ImageSets/Segmentation/train.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='RandomResize',
                scale=(2048, 512),
                ratio_range=(0.5, 2.0),
                keep_ratio=True),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs')
        ]))
val_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='PascalVOCDataset',
        data_root='data/VOCdevkit/VOC2012',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        ann_file='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', scale=(2048, 512), keep_ratio=True),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs')
        ]))
test_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='PascalVOCDataset',
        data_root='data/VOCdevkit/VOC2012',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        ann_file='ImageSets/Segmentation/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', scale=(2048, 512), keep_ratio=True),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs')
        ]))
val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])
test_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [dict(type='LocalVisBackend')]
visualizer = dict(
    type='SegLocalVisualizer',
    vis_backends=[dict(type='LocalVisBackend')],
    name='visualizer')
log_processor = dict(by_epoch=False)
log_level = 'INFO'
load_from = None
resume = True
tta_model = dict(type='SegTTAModel')
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=4e-05)
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=4e-05),
    clip_grad=None)
param_scheduler = [
    dict(
        type='PolyLR',
        eta_min=0.0001,
        power=0.9,
        begin=0,
        end=20000,
        by_epoch=False)
]
train_cfg = dict(type='IterBasedTrainLoop', max_iters=40000, val_interval=2000)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=200, log_metric_by_epoch=False),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', by_epoch=False, interval=2000),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='SegVisualizationHook'))
launcher = 'none'
work_dir = './work_dirs/advanced'

2023/02/13 23:22:13 - mmengine - WARNING - The "visualizer" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:13 - mmengine - WARNING - The "vis_backend" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:14 - mmengine - WARNING - The "model" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:14 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2023/02/13 23:22:14 - mmengine - WARNING - The "hook" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:14 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/02/13 23:22:14 - mmengine - WARNING - The "loop" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:14 - mmengine - WARNING - The "dataset" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:14 - mmengine - WARNING - The "transform" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:14 - mmengine - WARNING - The "data sampler" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:23 - mmengine - WARNING - The "optimizer wrapper constructor" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:23 - mmengine - WARNING - The "optimizer" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:23 - mmengine - WARNING - The "optim_wrapper" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:23 - mmengine - WARNING - The "parameter scheduler" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:23 - mmengine - WARNING - The "metric" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
2023/02/13 23:22:24 - mmengine - WARNING - The "weight initializer" registry in mmseg did not set import location. Fallback to call `mmseg.utils.register_all_modules` instead.
Name of parameter - Initialization information

backbone.learning_to_downsample.conv.conv.weight - torch.Size([32, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.learning_to_downsample.conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.dsconv1.depthwise_conv.conv.weight - torch.Size([32, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.learning_to_downsample.dsconv1.depthwise_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.dsconv1.depthwise_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.dsconv1.pointwise_conv.conv.weight - torch.Size([48, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.learning_to_downsample.dsconv1.pointwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.dsconv1.pointwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.dsconv2.depthwise_conv.conv.weight - torch.Size([48, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.learning_to_downsample.dsconv2.depthwise_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.dsconv2.depthwise_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.dsconv2.pointwise_conv.conv.weight - torch.Size([64, 48, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.learning_to_downsample.dsconv2.pointwise_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.learning_to_downsample.dsconv2.pointwise_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.0.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.0.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.0.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.0.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.0.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.0.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.0.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.0.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.0.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.1.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.1.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.1.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.1.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.1.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.1.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.1.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.1.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.1.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.2.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.2.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.2.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.2.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.2.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.2.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.2.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck1.2.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck1.2.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.0.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.0.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.0.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.0.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.0.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.0.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.0.conv.2.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.0.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.0.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.1.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.1.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.1.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.1.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.1.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.1.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.1.conv.2.conv.weight - torch.Size([96, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.1.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.1.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.2.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.2.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.2.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.2.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.2.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.2.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.2.conv.2.conv.weight - torch.Size([96, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck2.2.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck2.2.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.0.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.0.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.0.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.0.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.0.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.0.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.0.conv.2.conv.weight - torch.Size([128, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.0.conv.2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.0.conv.2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.1.conv.0.conv.weight - torch.Size([768, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.1.conv.0.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.1.conv.0.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.1.conv.1.conv.weight - torch.Size([768, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.1.conv.1.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.1.conv.1.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.1.conv.2.conv.weight - torch.Size([128, 768, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.1.conv.2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.1.conv.2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.2.conv.0.conv.weight - torch.Size([768, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.2.conv.0.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.2.conv.0.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.2.conv.1.conv.weight - torch.Size([768, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.2.conv.1.bn.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.2.conv.1.bn.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.2.conv.2.conv.weight - torch.Size([128, 768, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.bottleneck3.2.conv.2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.bottleneck3.2.conv.2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.ppm.0.1.conv.weight - torch.Size([32, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.ppm.0.1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.ppm.0.1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.ppm.1.1.conv.weight - torch.Size([32, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.ppm.1.1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.ppm.1.1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.ppm.2.1.conv.weight - torch.Size([32, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.ppm.2.1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.ppm.2.1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.ppm.3.1.conv.weight - torch.Size([32, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.ppm.3.1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.ppm.3.1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.out.conv.weight - torch.Size([128, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.global_feature_extractor.out.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.global_feature_extractor.out.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.feature_fusion.dwconv.conv.weight - torch.Size([128, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.feature_fusion.dwconv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.feature_fusion.dwconv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.feature_fusion.conv_lower_res.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.feature_fusion.conv_lower_res.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.feature_fusion.conv_lower_res.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.feature_fusion.conv_higher_res.conv.weight - torch.Size([128, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.feature_fusion.conv_higher_res.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.feature_fusion.conv_higher_res.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([21, 128, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([21]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.depthwise_conv.conv.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.depthwise_conv.conv.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.depthwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.depthwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.pointwise_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.pointwise_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.pointwise_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.weight - torch.Size([21, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.conv_seg.bias - torch.Size([21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.conv.weight - torch.Size([32, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.0.convs.0.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.weight - torch.Size([21, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.conv_seg.bias - torch.Size([21]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.conv.weight - torch.Size([32, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.1.convs.0.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023/02/13 23:22:24 - mmengine - INFO - Auto resumed from the latest checkpoint D:\workspace\openmmlab_tutorial\mmsegmentation\work_dirs\advanced\iter_20000.pth.
2023/02/13 23:22:25 - mmengine - INFO - Load checkpoint from D:\workspace\openmmlab_tutorial\mmsegmentation\work_dirs\advanced\iter_20000.pth
2023/02/13 23:22:25 - mmengine - INFO - resumed epoch: 0, iter: 20000
2023/02/13 23:22:25 - mmengine - INFO - Checkpoints will be saved to D:\workspace\openmmlab_tutorial\mmsegmentation\work_dirs\advanced.
2023/02/13 23:22:49 - mmengine - INFO - Iter(train) [20200/40000]  lr: 1.0000e-04  eta: 0:39:48  time: 0.1057  data_time: 0.0033  memory: 1827  loss: 0.0957  decode.loss_ce: 0.0440  decode.acc_seg: 84.1654  aux_0.loss_ce: 0.0192  aux_0.acc_seg: 81.3523  aux_1.loss_ce: 0.0324  aux_1.acc_seg: 71.1821
2023/02/13 23:23:10 - mmengine - INFO - Iter(train) [20400/40000]  lr: 1.0000e-04  eta: 0:37:14  time: 0.1078  data_time: 0.0032  memory: 1827  loss: 0.0879  decode.loss_ce: 0.0384  decode.acc_seg: 82.1892  aux_0.loss_ce: 0.0166  aux_0.acc_seg: 82.0324  aux_1.loss_ce: 0.0329  aux_1.acc_seg: 79.0224
2023/02/13 23:23:32 - mmengine - INFO - Iter(train) [20600/40000]  lr: 1.0000e-04  eta: 0:36:06  time: 0.1073  data_time: 0.0036  memory: 1827  loss: 0.0905  decode.loss_ce: 0.0386  decode.acc_seg: 71.7880  aux_0.loss_ce: 0.0171  aux_0.acc_seg: 71.7852  aux_1.loss_ce: 0.0348  aux_1.acc_seg: 71.5326
2023/02/13 23:23:53 - mmengine - INFO - Iter(train) [20800/40000]  lr: 1.0000e-04  eta: 0:35:24  time: 0.1082  data_time: 0.0034  memory: 1827  loss: 0.0908  decode.loss_ce: 0.0408  decode.acc_seg: 71.8557  aux_0.loss_ce: 0.0183  aux_0.acc_seg: 78.4196  aux_1.loss_ce: 0.0318  aux_1.acc_seg: 54.3783
2023/02/13 23:24:15 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:24:15 - mmengine - INFO - Iter(train) [21000/40000]  lr: 1.0000e-04  eta: 0:34:47  time: 0.1057  data_time: 0.0034  memory: 1827  loss: 0.0868  decode.loss_ce: 0.0383  decode.acc_seg: 86.0942  aux_0.loss_ce: 0.0171  aux_0.acc_seg: 86.5356  aux_1.loss_ce: 0.0314  aux_1.acc_seg: 76.7371
2023/02/13 23:24:36 - mmengine - INFO - Iter(train) [21200/40000]  lr: 1.0000e-04  eta: 0:34:14  time: 0.1068  data_time: 0.0033  memory: 1827  loss: 0.0919  decode.loss_ce: 0.0401  decode.acc_seg: 96.9023  aux_0.loss_ce: 0.0183  aux_0.acc_seg: 96.2100  aux_1.loss_ce: 0.0334  aux_1.acc_seg: 85.7314
2023/02/13 23:24:57 - mmengine - INFO - Iter(train) [21400/40000]  lr: 1.0000e-04  eta: 0:33:46  time: 0.1061  data_time: 0.0033  memory: 1826  loss: 0.0885  decode.loss_ce: 0.0382  decode.acc_seg: 80.6181  aux_0.loss_ce: 0.0167  aux_0.acc_seg: 77.2887  aux_1.loss_ce: 0.0336  aux_1.acc_seg: 49.8154
2023/02/13 23:25:19 - mmengine - INFO - Iter(train) [21600/40000]  lr: 1.0000e-04  eta: 0:33:19  time: 0.1059  data_time: 0.0034  memory: 1828  loss: 0.0837  decode.loss_ce: 0.0369  decode.acc_seg: 90.7360  aux_0.loss_ce: 0.0163  aux_0.acc_seg: 89.1325  aux_1.loss_ce: 0.0306  aux_1.acc_seg: 60.6264
2023/02/13 23:25:40 - mmengine - INFO - Iter(train) [21800/40000]  lr: 1.0000e-04  eta: 0:32:53  time: 0.1070  data_time: 0.0036  memory: 1828  loss: 0.0832  decode.loss_ce: 0.0364  decode.acc_seg: 82.6959  aux_0.loss_ce: 0.0162  aux_0.acc_seg: 82.8066  aux_1.loss_ce: 0.0306  aux_1.acc_seg: 71.5289
2023/02/13 23:26:01 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:26:01 - mmengine - INFO - Iter(train) [22000/40000]  lr: 1.0000e-04  eta: 0:32:28  time: 0.1052  data_time: 0.0035  memory: 1826  loss: 0.1054  decode.loss_ce: 0.0489  decode.acc_seg: 46.0154  aux_0.loss_ce: 0.0212  aux_0.acc_seg: 45.6558  aux_1.loss_ce: 0.0354  aux_1.acc_seg: 37.4352
2023/02/13 23:26:01 - mmengine - INFO - Saving checkpoint at 22000 iterations
2023/02/13 23:26:27 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:02:34  time: 0.0745  data_time: 0.0007  memory: 4201  
2023/02/13 23:26:33 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:01:21  time: 0.0548  data_time: 0.0007  memory: 3164  
2023/02/13 23:26:40 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:53  time: 0.0166  data_time: 0.0006  memory: 4204  
2023/02/13 23:26:46 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:35  time: 0.1377  data_time: 0.0009  memory: 4196  
2023/02/13 23:26:50 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0339  data_time: 0.0008  memory: 3165  
2023/02/13 23:26:54 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:10  time: 0.0319  data_time: 0.0008  memory: 4199  
2023/02/13 23:26:58 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:01  time: 0.0110  data_time: 0.0008  memory: 4197  
2023/02/13 23:26:59 - mmengine - INFO - per class results:
2023/02/13 23:26:59 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 87.45 | 96.84 |
|  aeroplane  | 46.86 | 72.58 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  4.76 |  4.88 |
|     boat    |  0.25 |  0.25 |
|    bottle   |  0.0  |  0.0  |
|     bus     | 74.65 | 77.77 |
|     car     | 62.18 | 73.85 |
|     cat     | 44.27 |  80.4 |
|    chair    |  0.0  |  0.0  |
|     cow     |  0.34 |  0.34 |
| diningtable | 17.52 | 24.16 |
|     dog     | 15.16 | 18.77 |
|    horse    | 24.25 | 41.89 |
|  motorbike  |  42.2 | 73.34 |
|    person   | 62.66 | 77.91 |
| pottedplant |  0.0  |  0.0  |
|    sheep    | 32.34 |  52.9 |
|     sofa    | 15.96 | 20.43 |
|    train    | 62.75 | 71.86 |
|  tvmonitor  | 37.24 | 50.73 |
+-------------+-------+-------+
2023/02/13 23:26:59 - mmengine - INFO - Iter(val) [1449/1449]  aAcc: 84.2100  mIoU: 30.0400  mAcc: 39.9500
2023/02/13 23:27:21 - mmengine - INFO - Iter(train) [22200/40000]  lr: 1.0000e-04  eta: 0:32:09  time: 0.1113  data_time: 0.0037  memory: 3164  loss: 0.0849  decode.loss_ce: 0.0363  decode.acc_seg: 92.3101  aux_0.loss_ce: 0.0165  aux_0.acc_seg: 92.8442  aux_1.loss_ce: 0.0321  aux_1.acc_seg: 74.5751
2023/02/13 23:27:42 - mmengine - INFO - Iter(train) [22400/40000]  lr: 1.0000e-04  eta: 0:31:48  time: 0.1109  data_time: 0.0033  memory: 1827  loss: 0.0820  decode.loss_ce: 0.0336  decode.acc_seg: 88.1620  aux_0.loss_ce: 0.0153  aux_0.acc_seg: 90.2397  aux_1.loss_ce: 0.0332  aux_1.acc_seg: 64.1342
2023/02/13 23:28:04 - mmengine - INFO - Iter(train) [22600/40000]  lr: 1.0000e-04  eta: 0:31:26  time: 0.1059  data_time: 0.0034  memory: 1827  loss: 0.0777  decode.loss_ce: 0.0337  decode.acc_seg: 91.1638  aux_0.loss_ce: 0.0151  aux_0.acc_seg: 89.5114  aux_1.loss_ce: 0.0288  aux_1.acc_seg: 82.6907
2023/02/13 23:28:26 - mmengine - INFO - Iter(train) [22800/40000]  lr: 1.0000e-04  eta: 0:31:05  time: 0.1080  data_time: 0.0036  memory: 1827  loss: 0.1076  decode.loss_ce: 0.0493  decode.acc_seg: 75.5133  aux_0.loss_ce: 0.0216  aux_0.acc_seg: 74.3186  aux_1.loss_ce: 0.0367  aux_1.acc_seg: 62.2060
2023/02/13 23:28:48 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:28:48 - mmengine - INFO - Iter(train) [23000/40000]  lr: 1.0000e-04  eta: 0:30:44  time: 0.1086  data_time: 0.0035  memory: 1827  loss: 0.0995  decode.loss_ce: 0.0436  decode.acc_seg: 74.8954  aux_0.loss_ce: 0.0190  aux_0.acc_seg: 73.2922  aux_1.loss_ce: 0.0369  aux_1.acc_seg: 47.1595
2023/02/13 23:29:09 - mmengine - INFO - Iter(train) [23200/40000]  lr: 1.0000e-04  eta: 0:30:23  time: 0.1114  data_time: 0.0034  memory: 1827  loss: 0.0824  decode.loss_ce: 0.0372  decode.acc_seg: 90.9455  aux_0.loss_ce: 0.0157  aux_0.acc_seg: 90.9151  aux_1.loss_ce: 0.0295  aux_1.acc_seg: 63.5431
2023/02/13 23:29:31 - mmengine - INFO - Iter(train) [23400/40000]  lr: 1.0000e-04  eta: 0:30:01  time: 0.1085  data_time: 0.0039  memory: 1827  loss: 0.0938  decode.loss_ce: 0.0408  decode.acc_seg: 77.2929  aux_0.loss_ce: 0.0177  aux_0.acc_seg: 74.4097  aux_1.loss_ce: 0.0352  aux_1.acc_seg: 73.7596
2023/02/13 23:29:53 - mmengine - INFO - Iter(train) [23600/40000]  lr: 1.0000e-04  eta: 0:29:40  time: 0.1105  data_time: 0.0036  memory: 1827  loss: 0.0932  decode.loss_ce: 0.0411  decode.acc_seg: 62.7181  aux_0.loss_ce: 0.0186  aux_0.acc_seg: 77.4554  aux_1.loss_ce: 0.0335  aux_1.acc_seg: 51.7112
2023/02/13 23:30:15 - mmengine - INFO - Iter(train) [23800/40000]  lr: 1.0000e-04  eta: 0:29:20  time: 0.1103  data_time: 0.0038  memory: 1827  loss: 0.0947  decode.loss_ce: 0.0412  decode.acc_seg: 91.1885  aux_0.loss_ce: 0.0181  aux_0.acc_seg: 90.6989  aux_1.loss_ce: 0.0355  aux_1.acc_seg: 67.5979
2023/02/13 23:30:37 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:30:37 - mmengine - INFO - Iter(train) [24000/40000]  lr: 1.0000e-04  eta: 0:28:58  time: 0.1090  data_time: 0.0034  memory: 1827  loss: 0.0798  decode.loss_ce: 0.0322  decode.acc_seg: 93.9093  aux_0.loss_ce: 0.0147  aux_0.acc_seg: 94.1648  aux_1.loss_ce: 0.0329  aux_1.acc_seg: 75.1523
2023/02/13 23:30:37 - mmengine - INFO - Saving checkpoint at 24000 iterations
2023/02/13 23:30:40 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:00:18  time: 0.0156  data_time: 0.0006  memory: 96  
2023/02/13 23:30:43 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:14  time: 0.0113  data_time: 0.0007  memory: 160  
2023/02/13 23:30:45 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:11  time: 0.0127  data_time: 0.0009  memory: 165  
2023/02/13 23:30:48 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:08  time: 0.0111  data_time: 0.0007  memory: 160  
2023/02/13 23:30:50 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:05  time: 0.0111  data_time: 0.0007  memory: 161  
2023/02/13 23:30:53 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:03  time: 0.0114  data_time: 0.0007  memory: 160  
2023/02/13 23:30:55 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:00  time: 0.0115  data_time: 0.0006  memory: 160  
2023/02/13 23:30:55 - mmengine - INFO - per class results:
2023/02/13 23:30:55 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  87.5 | 96.83 |
|  aeroplane  |  48.1 | 70.81 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  4.44 |  4.55 |
|     boat    |  0.23 |  0.23 |
|    bottle   |  0.0  |  0.0  |
|     bus     | 76.04 | 79.04 |
|     car     | 63.65 | 73.02 |
|     cat     | 44.29 |  79.5 |
|    chair    |  0.0  |  0.0  |
|     cow     |  0.33 |  0.34 |
| diningtable | 18.23 | 25.93 |
|     dog     | 15.35 | 18.57 |
|    horse    | 24.11 | 42.56 |
|  motorbike  | 42.91 |  72.5 |
|    person   | 62.74 | 78.18 |
| pottedplant |  0.0  |  0.0  |
|    sheep    | 32.25 | 56.77 |
|     sofa    | 16.01 |  20.6 |
|    train    | 62.43 | 73.76 |
|  tvmonitor  | 37.34 | 51.16 |
+-------------+-------+-------+
2023/02/13 23:30:55 - mmengine - INFO - Iter(val) [1449/1449]  aAcc: 84.2700  mIoU: 30.2800  mAcc: 40.2100
2023/02/13 23:31:17 - mmengine - INFO - Iter(train) [24200/40000]  lr: 1.0000e-04  eta: 0:28:37  time: 0.1095  data_time: 0.0036  memory: 1827  loss: 0.1161  decode.loss_ce: 0.0533  decode.acc_seg: 77.5623  aux_0.loss_ce: 0.0227  aux_0.acc_seg: 70.9734  aux_1.loss_ce: 0.0401  aux_1.acc_seg: 61.0609
2023/02/13 23:31:39 - mmengine - INFO - Iter(train) [24400/40000]  lr: 1.0000e-04  eta: 0:28:16  time: 0.1071  data_time: 0.0033  memory: 1828  loss: 0.0831  decode.loss_ce: 0.0372  decode.acc_seg: 85.1682  aux_0.loss_ce: 0.0157  aux_0.acc_seg: 84.7411  aux_1.loss_ce: 0.0302  aux_1.acc_seg: 70.4183
2023/02/13 23:32:01 - mmengine - INFO - Iter(train) [24600/40000]  lr: 1.0000e-04  eta: 0:27:54  time: 0.1099  data_time: 0.0037  memory: 1827  loss: 0.1094  decode.loss_ce: 0.0511  decode.acc_seg: 84.9281  aux_0.loss_ce: 0.0219  aux_0.acc_seg: 80.5771  aux_1.loss_ce: 0.0365  aux_1.acc_seg: 65.7753
2023/02/13 23:32:23 - mmengine - INFO - Iter(train) [24800/40000]  lr: 1.0000e-04  eta: 0:27:32  time: 0.1080  data_time: 0.0034  memory: 1829  loss: 0.0966  decode.loss_ce: 0.0416  decode.acc_seg: 68.5376  aux_0.loss_ce: 0.0188  aux_0.acc_seg: 68.8251  aux_1.loss_ce: 0.0363  aux_1.acc_seg: 33.5003
2023/02/13 23:32:44 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:32:44 - mmengine - INFO - Iter(train) [25000/40000]  lr: 1.0000e-04  eta: 0:27:10  time: 0.1091  data_time: 0.0034  memory: 1829  loss: 0.0823  decode.loss_ce: 0.0351  decode.acc_seg: 65.6039  aux_0.loss_ce: 0.0159  aux_0.acc_seg: 61.3898  aux_1.loss_ce: 0.0313  aux_1.acc_seg: 57.4550
2023/02/13 23:33:06 - mmengine - INFO - Iter(train) [25200/40000]  lr: 1.0000e-04  eta: 0:26:49  time: 0.1075  data_time: 0.0035  memory: 1827  loss: 0.1028  decode.loss_ce: 0.0459  decode.acc_seg: 72.9541  aux_0.loss_ce: 0.0198  aux_0.acc_seg: 68.6549  aux_1.loss_ce: 0.0371  aux_1.acc_seg: 43.7864
2023/02/13 23:33:28 - mmengine - INFO - Iter(train) [25400/40000]  lr: 1.0000e-04  eta: 0:26:27  time: 0.1112  data_time: 0.0032  memory: 1827  loss: 0.0919  decode.loss_ce: 0.0422  decode.acc_seg: 85.3005  aux_0.loss_ce: 0.0183  aux_0.acc_seg: 79.1561  aux_1.loss_ce: 0.0314  aux_1.acc_seg: 75.4531
2023/02/13 23:33:50 - mmengine - INFO - Iter(train) [25600/40000]  lr: 1.0000e-04  eta: 0:26:05  time: 0.1091  data_time: 0.0038  memory: 1827  loss: 0.0839  decode.loss_ce: 0.0353  decode.acc_seg: 90.3299  aux_0.loss_ce: 0.0166  aux_0.acc_seg: 88.5825  aux_1.loss_ce: 0.0320  aux_1.acc_seg: 70.6896
2023/02/13 23:34:11 - mmengine - INFO - Iter(train) [25800/40000]  lr: 1.0000e-04  eta: 0:25:43  time: 0.1093  data_time: 0.0034  memory: 1827  loss: 0.0806  decode.loss_ce: 0.0359  decode.acc_seg: 77.7587  aux_0.loss_ce: 0.0162  aux_0.acc_seg: 74.2575  aux_1.loss_ce: 0.0285  aux_1.acc_seg: 71.2547
2023/02/13 23:34:33 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:34:33 - mmengine - INFO - Iter(train) [26000/40000]  lr: 1.0000e-04  eta: 0:25:21  time: 0.1090  data_time: 0.0032  memory: 1827  loss: 0.0839  decode.loss_ce: 0.0375  decode.acc_seg: 93.3642  aux_0.loss_ce: 0.0159  aux_0.acc_seg: 92.8410  aux_1.loss_ce: 0.0305  aux_1.acc_seg: 92.4062
2023/02/13 23:34:33 - mmengine - INFO - Saving checkpoint at 26000 iterations
2023/02/13 23:34:36 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:00:14  time: 0.0123  data_time: 0.0005  memory: 96  
2023/02/13 23:34:39 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:12  time: 0.0111  data_time: 0.0009  memory: 160  
2023/02/13 23:34:41 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:10  time: 0.0111  data_time: 0.0008  memory: 165  
2023/02/13 23:34:43 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:07  time: 0.0111  data_time: 0.0005  memory: 160  
2023/02/13 23:34:46 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:05  time: 0.0116  data_time: 0.0005  memory: 161  
2023/02/13 23:34:48 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:02  time: 0.0125  data_time: 0.0009  memory: 160  
2023/02/13 23:34:51 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:00  time: 0.0145  data_time: 0.0005  memory: 160  
2023/02/13 23:34:52 - mmengine - INFO - per class results:
2023/02/13 23:34:52 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 87.46 | 96.81 |
|  aeroplane  | 47.31 | 71.31 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  4.31 |  4.4  |
|     boat    |  0.31 |  0.32 |
|    bottle   |  0.0  |  0.0  |
|     bus     | 76.69 | 80.95 |
|     car     | 63.93 | 75.35 |
|     cat     | 44.44 | 80.36 |
|    chair    |  0.0  |  0.0  |
|     cow     |  0.38 |  0.38 |
| diningtable | 17.85 | 24.62 |
|     dog     | 14.66 | 17.41 |
|    horse    | 23.86 | 41.93 |
|  motorbike  | 42.06 | 72.05 |
|    person   | 62.63 |  76.8 |
| pottedplant |  0.0  |  0.0  |
|    sheep    | 32.35 | 56.66 |
|     sofa    | 15.61 | 20.27 |
|    train    |  63.3 | 75.71 |
|  tvmonitor  | 37.17 | 52.03 |
+-------------+-------+-------+
2023/02/13 23:34:52 - mmengine - INFO - Iter(val) [1449/1449]  aAcc: 84.2600  mIoU: 30.2100  mAcc: 40.3500
2023/02/13 23:35:14 - mmengine - INFO - Iter(train) [26200/40000]  lr: 1.0000e-04  eta: 0:25:00  time: 0.1075  data_time: 0.0032  memory: 1827  loss: 0.0828  decode.loss_ce: 0.0357  decode.acc_seg: 78.3393  aux_0.loss_ce: 0.0160  aux_0.acc_seg: 78.9747  aux_1.loss_ce: 0.0311  aux_1.acc_seg: 53.7303
2023/02/13 23:35:36 - mmengine - INFO - Iter(train) [26400/40000]  lr: 1.0000e-04  eta: 0:24:39  time: 0.1094  data_time: 0.0031  memory: 1827  loss: 0.1164  decode.loss_ce: 0.0511  decode.acc_seg: 83.3138  aux_0.loss_ce: 0.0222  aux_0.acc_seg: 80.2537  aux_1.loss_ce: 0.0430  aux_1.acc_seg: 48.4905
2023/02/13 23:35:57 - mmengine - INFO - Iter(train) [26600/40000]  lr: 1.0000e-04  eta: 0:24:17  time: 0.1078  data_time: 0.0034  memory: 1827  loss: 0.1020  decode.loss_ce: 0.0445  decode.acc_seg: 82.6400  aux_0.loss_ce: 0.0204  aux_0.acc_seg: 82.7018  aux_1.loss_ce: 0.0371  aux_1.acc_seg: 80.8030
2023/02/13 23:36:19 - mmengine - INFO - Iter(train) [26800/40000]  lr: 1.0000e-04  eta: 0:23:56  time: 0.1146  data_time: 0.0036  memory: 1829  loss: 0.0823  decode.loss_ce: 0.0366  decode.acc_seg: 83.3429  aux_0.loss_ce: 0.0163  aux_0.acc_seg: 83.3434  aux_1.loss_ce: 0.0294  aux_1.acc_seg: 60.6611
2023/02/13 23:36:41 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:36:41 - mmengine - INFO - Iter(train) [27000/40000]  lr: 1.0000e-04  eta: 0:23:34  time: 0.1094  data_time: 0.0036  memory: 1829  loss: 0.0789  decode.loss_ce: 0.0345  decode.acc_seg: 82.0932  aux_0.loss_ce: 0.0152  aux_0.acc_seg: 80.9449  aux_1.loss_ce: 0.0293  aux_1.acc_seg: 53.0765
2023/02/13 23:37:03 - mmengine - INFO - Iter(train) [27200/40000]  lr: 1.0000e-04  eta: 0:23:13  time: 0.1091  data_time: 0.0033  memory: 1827  loss: 0.0834  decode.loss_ce: 0.0363  decode.acc_seg: 81.2363  aux_0.loss_ce: 0.0160  aux_0.acc_seg: 81.1399  aux_1.loss_ce: 0.0311  aux_1.acc_seg: 66.1766
2023/02/13 23:37:25 - mmengine - INFO - Iter(train) [27400/40000]  lr: 1.0000e-04  eta: 0:22:51  time: 0.1090  data_time: 0.0034  memory: 1827  loss: 0.0777  decode.loss_ce: 0.0314  decode.acc_seg: 65.9721  aux_0.loss_ce: 0.0143  aux_0.acc_seg: 63.4887  aux_1.loss_ce: 0.0321  aux_1.acc_seg: 47.8274
2023/02/13 23:37:46 - mmengine - INFO - Iter(train) [27600/40000]  lr: 1.0000e-04  eta: 0:22:29  time: 0.1098  data_time: 0.0035  memory: 1827  loss: 0.0837  decode.loss_ce: 0.0363  decode.acc_seg: 89.2300  aux_0.loss_ce: 0.0161  aux_0.acc_seg: 83.0378  aux_1.loss_ce: 0.0313  aux_1.acc_seg: 69.4972
2023/02/13 23:38:08 - mmengine - INFO - Iter(train) [27800/40000]  lr: 1.0000e-04  eta: 0:22:08  time: 0.1097  data_time: 0.0035  memory: 1827  loss: 0.0778  decode.loss_ce: 0.0362  decode.acc_seg: 95.1530  aux_0.loss_ce: 0.0156  aux_0.acc_seg: 92.5971  aux_1.loss_ce: 0.0261  aux_1.acc_seg: 70.5687
2023/02/13 23:38:30 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:38:30 - mmengine - INFO - Iter(train) [28000/40000]  lr: 1.0000e-04  eta: 0:21:46  time: 0.1096  data_time: 0.0034  memory: 1827  loss: 0.1016  decode.loss_ce: 0.0468  decode.acc_seg: 65.4289  aux_0.loss_ce: 0.0198  aux_0.acc_seg: 66.7677  aux_1.loss_ce: 0.0350  aux_1.acc_seg: 56.1657
2023/02/13 23:38:30 - mmengine - INFO - Saving checkpoint at 28000 iterations
2023/02/13 23:38:33 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:00:15  time: 0.0111  data_time: 0.0010  memory: 96  
2023/02/13 23:38:36 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:12  time: 0.0110  data_time: 0.0008  memory: 160  
2023/02/13 23:38:38 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:10  time: 0.0127  data_time: 0.0007  memory: 165  
2023/02/13 23:38:40 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:07  time: 0.0115  data_time: 0.0004  memory: 160  
2023/02/13 23:38:43 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:05  time: 0.0111  data_time: 0.0005  memory: 161  
2023/02/13 23:38:46 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:03  time: 0.0158  data_time: 0.0005  memory: 160  
2023/02/13 23:38:48 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:00  time: 0.0116  data_time: 0.0006  memory: 160  
2023/02/13 23:38:49 - mmengine - INFO - per class results:
2023/02/13 23:38:49 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 87.47 | 96.81 |
|  aeroplane  | 47.21 | 72.51 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  5.11 |  5.23 |
|     boat    |  0.56 |  0.57 |
|    bottle   |  0.0  |  0.0  |
|     bus     | 76.51 | 80.26 |
|     car     | 64.29 | 74.15 |
|     cat     | 44.39 |  79.8 |
|    chair    |  0.0  |  0.0  |
|     cow     |  0.18 |  0.18 |
| diningtable | 19.65 | 27.08 |
|     dog     | 15.57 | 18.36 |
|    horse    | 23.29 | 39.74 |
|  motorbike  |  42.8 | 72.67 |
|    person   | 63.45 | 77.53 |
| pottedplant |  0.0  |  0.0  |
|    sheep    | 31.82 | 58.33 |
|     sofa    | 17.17 | 22.89 |
|    train    | 63.66 | 74.61 |
|  tvmonitor  | 36.72 | 52.37 |
+-------------+-------+-------+
2023/02/13 23:38:49 - mmengine - INFO - Iter(val) [1449/1449]  aAcc: 84.3300  mIoU: 30.4700  mAcc: 40.6200
2023/02/13 23:39:11 - mmengine - INFO - Iter(train) [28200/40000]  lr: 1.0000e-04  eta: 0:21:24  time: 0.1104  data_time: 0.0035  memory: 1829  loss: 0.0879  decode.loss_ce: 0.0382  decode.acc_seg: 65.3176  aux_0.loss_ce: 0.0175  aux_0.acc_seg: 71.5008  aux_1.loss_ce: 0.0322  aux_1.acc_seg: 54.8024
2023/02/13 23:39:33 - mmengine - INFO - Iter(train) [28400/40000]  lr: 1.0000e-04  eta: 0:21:03  time: 0.1090  data_time: 0.0039  memory: 1827  loss: 0.0920  decode.loss_ce: 0.0397  decode.acc_seg: 81.6263  aux_0.loss_ce: 0.0171  aux_0.acc_seg: 80.8785  aux_1.loss_ce: 0.0352  aux_1.acc_seg: 63.5303
2023/02/13 23:39:54 - mmengine - INFO - Iter(train) [28600/40000]  lr: 1.0000e-04  eta: 0:20:41  time: 0.1109  data_time: 0.0037  memory: 1827  loss: 0.1103  decode.loss_ce: 0.0514  decode.acc_seg: 73.0456  aux_0.loss_ce: 0.0222  aux_0.acc_seg: 68.1373  aux_1.loss_ce: 0.0367  aux_1.acc_seg: 40.8983
2023/02/13 23:40:17 - mmengine - INFO - Iter(train) [28800/40000]  lr: 1.0000e-04  eta: 0:20:20  time: 0.1095  data_time: 0.0033  memory: 1829  loss: 0.0801  decode.loss_ce: 0.0333  decode.acc_seg: 91.6363  aux_0.loss_ce: 0.0154  aux_0.acc_seg: 93.3745  aux_1.loss_ce: 0.0314  aux_1.acc_seg: 84.7890
2023/02/13 23:40:38 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:40:38 - mmengine - INFO - Iter(train) [29000/40000]  lr: 1.0000e-04  eta: 0:19:58  time: 0.1122  data_time: 0.0035  memory: 1827  loss: 0.1004  decode.loss_ce: 0.0439  decode.acc_seg: 69.8994  aux_0.loss_ce: 0.0194  aux_0.acc_seg: 68.4975  aux_1.loss_ce: 0.0371  aux_1.acc_seg: 64.7532
2023/02/13 23:41:00 - mmengine - INFO - Iter(train) [29200/40000]  lr: 1.0000e-04  eta: 0:19:36  time: 0.1103  data_time: 0.0035  memory: 1827  loss: 0.0936  decode.loss_ce: 0.0408  decode.acc_seg: 59.6307  aux_0.loss_ce: 0.0179  aux_0.acc_seg: 58.7145  aux_1.loss_ce: 0.0349  aux_1.acc_seg: 50.2413
2023/02/13 23:41:22 - mmengine - INFO - Iter(train) [29400/40000]  lr: 1.0000e-04  eta: 0:19:14  time: 0.1078  data_time: 0.0037  memory: 1827  loss: 0.1104  decode.loss_ce: 0.0499  decode.acc_seg: 89.2369  aux_0.loss_ce: 0.0204  aux_0.acc_seg: 84.1226  aux_1.loss_ce: 0.0401  aux_1.acc_seg: 68.0084
2023/02/13 23:41:44 - mmengine - INFO - Iter(train) [29600/40000]  lr: 1.0000e-04  eta: 0:18:52  time: 0.1086  data_time: 0.0034  memory: 1829  loss: 0.1066  decode.loss_ce: 0.0480  decode.acc_seg: 72.0598  aux_0.loss_ce: 0.0210  aux_0.acc_seg: 73.9773  aux_1.loss_ce: 0.0376  aux_1.acc_seg: 74.3913
2023/02/13 23:42:05 - mmengine - INFO - Iter(train) [29800/40000]  lr: 1.0000e-04  eta: 0:18:31  time: 0.1085  data_time: 0.0036  memory: 1827  loss: 0.0832  decode.loss_ce: 0.0353  decode.acc_seg: 84.8719  aux_0.loss_ce: 0.0159  aux_0.acc_seg: 85.1888  aux_1.loss_ce: 0.0320  aux_1.acc_seg: 79.5504
2023/02/13 23:42:27 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:42:27 - mmengine - INFO - Iter(train) [30000/40000]  lr: 1.0000e-04  eta: 0:18:09  time: 0.1062  data_time: 0.0032  memory: 1827  loss: 0.0887  decode.loss_ce: 0.0399  decode.acc_seg: 73.6715  aux_0.loss_ce: 0.0175  aux_0.acc_seg: 76.9482  aux_1.loss_ce: 0.0313  aux_1.acc_seg: 65.9065
2023/02/13 23:42:27 - mmengine - INFO - Saving checkpoint at 30000 iterations
2023/02/13 23:42:30 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:00:14  time: 0.0111  data_time: 0.0009  memory: 96  
2023/02/13 23:42:33 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:11  time: 0.0110  data_time: 0.0008  memory: 160  
2023/02/13 23:42:35 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:09  time: 0.0126  data_time: 0.0007  memory: 165  
2023/02/13 23:42:38 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:08  time: 0.0151  data_time: 0.0007  memory: 160  
2023/02/13 23:42:41 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:05  time: 0.0131  data_time: 0.0010  memory: 161  
2023/02/13 23:42:43 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:03  time: 0.0121  data_time: 0.0008  memory: 160  
2023/02/13 23:42:45 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:00  time: 0.0114  data_time: 0.0007  memory: 160  
2023/02/13 23:42:46 - mmengine - INFO - per class results:
2023/02/13 23:42:46 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 87.51 | 96.76 |
|  aeroplane  | 47.11 | 73.32 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  4.39 |  4.48 |
|     boat    |  0.47 |  0.48 |
|    bottle   |  0.0  |  0.0  |
|     bus     | 76.69 | 80.45 |
|     car     | 65.03 | 76.43 |
|     cat     | 43.82 |  80.3 |
|    chair    |  0.0  |  0.0  |
|     cow     |  0.12 |  0.12 |
| diningtable | 19.39 | 26.24 |
|     dog     | 14.14 | 16.86 |
|    horse    | 24.11 | 40.71 |
|  motorbike  | 43.67 | 70.48 |
|    person   | 63.09 |  78.3 |
| pottedplant |  0.0  |  0.0  |
|    sheep    | 33.03 | 57.38 |
|     sofa    | 16.65 | 21.91 |
|    train    | 64.03 | 75.74 |
|  tvmonitor  | 37.34 | 54.88 |
+-------------+-------+-------+
2023/02/13 23:42:46 - mmengine - INFO - Iter(val) [1449/1449]  aAcc: 84.3500  mIoU: 30.5000  mAcc: 40.7100
2023/02/13 23:43:08 - mmengine - INFO - Iter(train) [30200/40000]  lr: 1.0000e-04  eta: 0:17:47  time: 0.1092  data_time: 0.0034  memory: 1827  loss: 0.0902  decode.loss_ce: 0.0390  decode.acc_seg: 92.8545  aux_0.loss_ce: 0.0174  aux_0.acc_seg: 90.0117  aux_1.loss_ce: 0.0338  aux_1.acc_seg: 58.7432
2023/02/13 23:43:30 - mmengine - INFO - Iter(train) [30400/40000]  lr: 1.0000e-04  eta: 0:17:25  time: 0.1116  data_time: 0.0035  memory: 1828  loss: 0.0998  decode.loss_ce: 0.0437  decode.acc_seg: 59.2048  aux_0.loss_ce: 0.0187  aux_0.acc_seg: 46.5269  aux_1.loss_ce: 0.0373  aux_1.acc_seg: 36.7465
2023/02/13 23:43:51 - mmengine - INFO - Iter(train) [30600/40000]  lr: 1.0000e-04  eta: 0:17:03  time: 0.1064  data_time: 0.0032  memory: 1827  loss: 0.0918  decode.loss_ce: 0.0421  decode.acc_seg: 73.8806  aux_0.loss_ce: 0.0177  aux_0.acc_seg: 72.6712  aux_1.loss_ce: 0.0320  aux_1.acc_seg: 68.5718
2023/02/13 23:44:13 - mmengine - INFO - Iter(train) [30800/40000]  lr: 1.0000e-04  eta: 0:16:41  time: 0.1064  data_time: 0.0036  memory: 1827  loss: 0.0828  decode.loss_ce: 0.0358  decode.acc_seg: 80.9585  aux_0.loss_ce: 0.0164  aux_0.acc_seg: 75.6326  aux_1.loss_ce: 0.0306  aux_1.acc_seg: 51.7797
2023/02/13 23:44:35 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:44:35 - mmengine - INFO - Iter(train) [31000/40000]  lr: 1.0000e-04  eta: 0:16:19  time: 0.1094  data_time: 0.0035  memory: 1827  loss: 0.0959  decode.loss_ce: 0.0401  decode.acc_seg: 94.6826  aux_0.loss_ce: 0.0177  aux_0.acc_seg: 88.3484  aux_1.loss_ce: 0.0382  aux_1.acc_seg: 70.4094
2023/02/13 23:44:56 - mmengine - INFO - Iter(train) [31200/40000]  lr: 1.0000e-04  eta: 0:15:58  time: 0.1050  data_time: 0.0034  memory: 1827  loss: 0.1029  decode.loss_ce: 0.0463  decode.acc_seg: 76.8859  aux_0.loss_ce: 0.0191  aux_0.acc_seg: 76.1206  aux_1.loss_ce: 0.0375  aux_1.acc_seg: 40.2669
2023/02/13 23:45:18 - mmengine - INFO - Iter(train) [31400/40000]  lr: 1.0000e-04  eta: 0:15:35  time: 0.1061  data_time: 0.0033  memory: 1827  loss: 0.0991  decode.loss_ce: 0.0440  decode.acc_seg: 79.1713  aux_0.loss_ce: 0.0194  aux_0.acc_seg: 79.4300  aux_1.loss_ce: 0.0357  aux_1.acc_seg: 61.4540
2023/02/13 23:45:39 - mmengine - INFO - Iter(train) [31600/40000]  lr: 1.0000e-04  eta: 0:15:13  time: 0.1065  data_time: 0.0034  memory: 1828  loss: 0.1083  decode.loss_ce: 0.0500  decode.acc_seg: 71.0303  aux_0.loss_ce: 0.0218  aux_0.acc_seg: 66.7467  aux_1.loss_ce: 0.0365  aux_1.acc_seg: 53.7274
2023/02/13 23:46:00 - mmengine - INFO - Iter(train) [31800/40000]  lr: 1.0000e-04  eta: 0:14:51  time: 0.1097  data_time: 0.0036  memory: 1827  loss: 0.0814  decode.loss_ce: 0.0346  decode.acc_seg: 89.7317  aux_0.loss_ce: 0.0153  aux_0.acc_seg: 92.5522  aux_1.loss_ce: 0.0315  aux_1.acc_seg: 79.7742
2023/02/13 23:46:21 - mmengine - INFO - Exp name: fast_scnn_voc12_20230213_232209
2023/02/13 23:46:21 - mmengine - INFO - Iter(train) [32000/40000]  lr: 1.0000e-04  eta: 0:14:29  time: 0.1048  data_time: 0.0034  memory: 1827  loss: 0.1022  decode.loss_ce: 0.0468  decode.acc_seg: 87.5895  aux_0.loss_ce: 0.0209  aux_0.acc_seg: 86.4506  aux_1.loss_ce: 0.0345  aux_1.acc_seg: 64.4411
2023/02/13 23:46:21 - mmengine - INFO - Saving checkpoint at 32000 iterations
2023/02/13 23:46:24 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:00:13  time: 0.0110  data_time: 0.0008  memory: 96  
2023/02/13 23:46:27 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:12  time: 0.0151  data_time: 0.0010  memory: 160  
2023/02/13 23:46:30 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:10  time: 0.0150  data_time: 0.0008  memory: 165  
2023/02/13 23:46:32 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:08  time: 0.0110  data_time: 0.0010  memory: 160  
2023/02/13 23:46:34 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:05  time: 0.0126  data_time: 0.0007  memory: 161  
2023/02/13 23:46:37 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:03  time: 0.0113  data_time: 0.0010  memory: 160  
2023/02/13 23:46:39 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:00  time: 0.0152  data_time: 0.0010  memory: 160  
2023/02/13 23:46:40 - mmengine - INFO - per class results:
2023/02/13 23:46:40 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 87.55 | 96.92 |
|  aeroplane  | 46.98 | 72.87 |
|   bicycle   |  0.0  |  0.0  |
|     bird    |  5.41 |  5.56 |
|     boat    |  0.26 |  0.26 |
|    bottle   |  0.0  |  0.0  |
|     bus     | 76.13 | 79.79 |
|     car     | 64.93 | 74.63 |
|     cat     | 44.43 | 79.15 |
|    chair    |  0.0  |  0.0  |
|     cow     |  0.15 |  0.15 |
| diningtable | 18.67 | 26.64 |
|     dog     | 15.14 | 18.38 |
|    horse    | 25.52 | 45.67 |
|  motorbike  | 43.27 | 72.24 |
|    person   | 62.94 | 77.44 |
| pottedplant |  0.0  |  0.0  |
|    sheep    | 33.84 | 55.35 |
|     sofa    | 16.06 | 21.34 |
|    train    | 64.65 | 73.79 |
|  tvmonitor  | 37.33 | 50.29 |
+-------------+-------+-------+
2023/02/13 23:46:40 - mmengine - INFO - Iter(val) [1449/1449]  aAcc: 84.3800  mIoU: 30.6300  mAcc: 40.5000
